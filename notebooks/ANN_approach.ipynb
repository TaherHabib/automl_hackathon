{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504b2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3998785",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '../automl-fall-school-2021-hackathon/data_train.csv'\n",
    "test_data_path = '../automl-fall-school-2021-hackathon/data_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74951b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_data_path) # consists of 50000 rows and 100 features \n",
    "# (V25_6, V26_5, V47_8, V52_6, V56_7,v69_5, V74_4,V83_5, V99_7 and V100_6 are categorical)\n",
    "    \n",
    "test_data = pd.read_csv(test_data_path) # consists of 66238 rows and 100 features\n",
    "# last column is dummy column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e2f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping useless columns from the training data\n",
    "train_data = train_data.drop(['V5', 'V23', 'V34', 'V44', 'V66', 'V86' ], axis=1)\n",
    "\n",
    "# Dropping all rows with any nan values\n",
    "train_data = train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50442df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V91</th>\n",
       "      <th>V92</th>\n",
       "      <th>V93</th>\n",
       "      <th>V94</th>\n",
       "      <th>V95</th>\n",
       "      <th>V96</th>\n",
       "      <th>V97</th>\n",
       "      <th>V98</th>\n",
       "      <th>V99</th>\n",
       "      <th>V100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DO</td>\n",
       "      <td>1819.870220</td>\n",
       "      <td>-1049.683290</td>\n",
       "      <td>-1097.551530</td>\n",
       "      <td>419.668781</td>\n",
       "      <td>874.102780</td>\n",
       "      <td>-5646.018630</td>\n",
       "      <td>-1745.922933</td>\n",
       "      <td>1257.986598</td>\n",
       "      <td>876.953151</td>\n",
       "      <td>...</td>\n",
       "      <td>907.050893</td>\n",
       "      <td>118.392812</td>\n",
       "      <td>3723.116140</td>\n",
       "      <td>570.075438</td>\n",
       "      <td>-833.691337</td>\n",
       "      <td>2797.442697</td>\n",
       "      <td>306.103167</td>\n",
       "      <td>863.381036</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT</td>\n",
       "      <td>5338.339092</td>\n",
       "      <td>-896.336093</td>\n",
       "      <td>-169.203551</td>\n",
       "      <td>420.113222</td>\n",
       "      <td>875.912844</td>\n",
       "      <td>990.045875</td>\n",
       "      <td>-490.424433</td>\n",
       "      <td>-315.042299</td>\n",
       "      <td>871.569241</td>\n",
       "      <td>...</td>\n",
       "      <td>930.631453</td>\n",
       "      <td>144.072375</td>\n",
       "      <td>4081.401627</td>\n",
       "      <td>447.463827</td>\n",
       "      <td>-722.890871</td>\n",
       "      <td>-9411.034432</td>\n",
       "      <td>265.863035</td>\n",
       "      <td>449.478649</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DZ</td>\n",
       "      <td>376.999942</td>\n",
       "      <td>-457.473122</td>\n",
       "      <td>-12.817029</td>\n",
       "      <td>420.887318</td>\n",
       "      <td>875.878783</td>\n",
       "      <td>-290.534515</td>\n",
       "      <td>-275.232733</td>\n",
       "      <td>-373.929651</td>\n",
       "      <td>878.186110</td>\n",
       "      <td>...</td>\n",
       "      <td>940.574847</td>\n",
       "      <td>144.645611</td>\n",
       "      <td>133.532673</td>\n",
       "      <td>329.363657</td>\n",
       "      <td>-760.617723</td>\n",
       "      <td>1389.481995</td>\n",
       "      <td>303.399314</td>\n",
       "      <td>417.676998</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EF</td>\n",
       "      <td>6633.434350</td>\n",
       "      <td>-1139.578274</td>\n",
       "      <td>562.928815</td>\n",
       "      <td>422.742834</td>\n",
       "      <td>869.440917</td>\n",
       "      <td>1062.673252</td>\n",
       "      <td>-1296.822459</td>\n",
       "      <td>-638.085049</td>\n",
       "      <td>878.147031</td>\n",
       "      <td>...</td>\n",
       "      <td>940.457668</td>\n",
       "      <td>141.576882</td>\n",
       "      <td>-840.502401</td>\n",
       "      <td>439.238111</td>\n",
       "      <td>-763.469013</td>\n",
       "      <td>-4605.075778</td>\n",
       "      <td>316.002515</td>\n",
       "      <td>502.876430</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DW</td>\n",
       "      <td>-3147.858218</td>\n",
       "      <td>-1315.076756</td>\n",
       "      <td>-1640.884995</td>\n",
       "      <td>422.072351</td>\n",
       "      <td>869.445753</td>\n",
       "      <td>-2577.051356</td>\n",
       "      <td>-693.467931</td>\n",
       "      <td>-41.339765</td>\n",
       "      <td>881.863079</td>\n",
       "      <td>...</td>\n",
       "      <td>794.539528</td>\n",
       "      <td>146.561762</td>\n",
       "      <td>1052.697529</td>\n",
       "      <td>51.096985</td>\n",
       "      <td>-781.918944</td>\n",
       "      <td>-4423.057820</td>\n",
       "      <td>269.091842</td>\n",
       "      <td>377.266730</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>CK</td>\n",
       "      <td>637.475113</td>\n",
       "      <td>-509.604945</td>\n",
       "      <td>68.401386</td>\n",
       "      <td>420.166775</td>\n",
       "      <td>875.272112</td>\n",
       "      <td>1531.888185</td>\n",
       "      <td>-224.819844</td>\n",
       "      <td>-390.949253</td>\n",
       "      <td>879.640508</td>\n",
       "      <td>...</td>\n",
       "      <td>1001.366049</td>\n",
       "      <td>138.985893</td>\n",
       "      <td>-23.071407</td>\n",
       "      <td>397.246282</td>\n",
       "      <td>-762.546047</td>\n",
       "      <td>-138.500465</td>\n",
       "      <td>272.495833</td>\n",
       "      <td>433.128325</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>EH</td>\n",
       "      <td>4138.165843</td>\n",
       "      <td>-677.186860</td>\n",
       "      <td>-221.581569</td>\n",
       "      <td>420.679631</td>\n",
       "      <td>880.584017</td>\n",
       "      <td>548.687942</td>\n",
       "      <td>33.667961</td>\n",
       "      <td>-30.767771</td>\n",
       "      <td>877.663037</td>\n",
       "      <td>...</td>\n",
       "      <td>1083.243078</td>\n",
       "      <td>145.314090</td>\n",
       "      <td>-164.709859</td>\n",
       "      <td>47.029279</td>\n",
       "      <td>-788.976170</td>\n",
       "      <td>5319.476900</td>\n",
       "      <td>297.987579</td>\n",
       "      <td>503.791602</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>CW</td>\n",
       "      <td>-6576.137973</td>\n",
       "      <td>-336.252493</td>\n",
       "      <td>-259.617310</td>\n",
       "      <td>420.281572</td>\n",
       "      <td>875.880073</td>\n",
       "      <td>-2187.145059</td>\n",
       "      <td>-492.867469</td>\n",
       "      <td>-735.107623</td>\n",
       "      <td>881.855471</td>\n",
       "      <td>...</td>\n",
       "      <td>897.097722</td>\n",
       "      <td>145.853874</td>\n",
       "      <td>1025.685762</td>\n",
       "      <td>297.677559</td>\n",
       "      <td>-809.616688</td>\n",
       "      <td>4874.145139</td>\n",
       "      <td>363.358205</td>\n",
       "      <td>439.075537</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>BW</td>\n",
       "      <td>-16736.671310</td>\n",
       "      <td>-334.539742</td>\n",
       "      <td>-521.619908</td>\n",
       "      <td>421.936298</td>\n",
       "      <td>875.470550</td>\n",
       "      <td>-1832.102252</td>\n",
       "      <td>-1588.345249</td>\n",
       "      <td>-157.507237</td>\n",
       "      <td>884.924972</td>\n",
       "      <td>...</td>\n",
       "      <td>833.384112</td>\n",
       "      <td>120.439889</td>\n",
       "      <td>71.780507</td>\n",
       "      <td>271.855923</td>\n",
       "      <td>-826.082828</td>\n",
       "      <td>-970.042171</td>\n",
       "      <td>339.248619</td>\n",
       "      <td>416.835122</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>AH</td>\n",
       "      <td>6714.333791</td>\n",
       "      <td>-687.583312</td>\n",
       "      <td>-1147.792710</td>\n",
       "      <td>421.541398</td>\n",
       "      <td>877.268047</td>\n",
       "      <td>5715.839679</td>\n",
       "      <td>719.963384</td>\n",
       "      <td>-272.819246</td>\n",
       "      <td>872.883880</td>\n",
       "      <td>...</td>\n",
       "      <td>1085.039623</td>\n",
       "      <td>150.996109</td>\n",
       "      <td>1585.494960</td>\n",
       "      <td>430.515214</td>\n",
       "      <td>-764.690738</td>\n",
       "      <td>7157.947224</td>\n",
       "      <td>297.733136</td>\n",
       "      <td>427.241770</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49972 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class            V1           V2           V3          V4          V6  \\\n",
       "0        DO   1819.870220 -1049.683290 -1097.551530  419.668781  874.102780   \n",
       "1        AT   5338.339092  -896.336093  -169.203551  420.113222  875.912844   \n",
       "2        DZ    376.999942  -457.473122   -12.817029  420.887318  875.878783   \n",
       "3        EF   6633.434350 -1139.578274   562.928815  422.742834  869.440917   \n",
       "4        DW  -3147.858218 -1315.076756 -1640.884995  422.072351  869.445753   \n",
       "...     ...           ...          ...          ...         ...         ...   \n",
       "49995    CK    637.475113  -509.604945    68.401386  420.166775  875.272112   \n",
       "49996    EH   4138.165843  -677.186860  -221.581569  420.679631  880.584017   \n",
       "49997    CW  -6576.137973  -336.252493  -259.617310  420.281572  875.880073   \n",
       "49998    BW -16736.671310  -334.539742  -521.619908  421.936298  875.470550   \n",
       "49999    AH   6714.333791  -687.583312 -1147.792710  421.541398  877.268047   \n",
       "\n",
       "                V7           V8           V9         V10  ...          V91  \\\n",
       "0     -5646.018630 -1745.922933  1257.986598  876.953151  ...   907.050893   \n",
       "1       990.045875  -490.424433  -315.042299  871.569241  ...   930.631453   \n",
       "2      -290.534515  -275.232733  -373.929651  878.186110  ...   940.574847   \n",
       "3      1062.673252 -1296.822459  -638.085049  878.147031  ...   940.457668   \n",
       "4     -2577.051356  -693.467931   -41.339765  881.863079  ...   794.539528   \n",
       "...            ...          ...          ...         ...  ...          ...   \n",
       "49995  1531.888185  -224.819844  -390.949253  879.640508  ...  1001.366049   \n",
       "49996   548.687942    33.667961   -30.767771  877.663037  ...  1083.243078   \n",
       "49997 -2187.145059  -492.867469  -735.107623  881.855471  ...   897.097722   \n",
       "49998 -1832.102252 -1588.345249  -157.507237  884.924972  ...   833.384112   \n",
       "49999  5715.839679   719.963384  -272.819246  872.883880  ...  1085.039623   \n",
       "\n",
       "              V92          V93         V94         V95          V96  \\\n",
       "0      118.392812  3723.116140  570.075438 -833.691337  2797.442697   \n",
       "1      144.072375  4081.401627  447.463827 -722.890871 -9411.034432   \n",
       "2      144.645611   133.532673  329.363657 -760.617723  1389.481995   \n",
       "3      141.576882  -840.502401  439.238111 -763.469013 -4605.075778   \n",
       "4      146.561762  1052.697529   51.096985 -781.918944 -4423.057820   \n",
       "...           ...          ...         ...         ...          ...   \n",
       "49995  138.985893   -23.071407  397.246282 -762.546047  -138.500465   \n",
       "49996  145.314090  -164.709859   47.029279 -788.976170  5319.476900   \n",
       "49997  145.853874  1025.685762  297.677559 -809.616688  4874.145139   \n",
       "49998  120.439889    71.780507  271.855923 -826.082828  -970.042171   \n",
       "49999  150.996109  1585.494960  430.515214 -764.690738  7157.947224   \n",
       "\n",
       "              V97         V98  V99  V100  \n",
       "0      306.103167  863.381036    D     D  \n",
       "1      265.863035  449.478649    B     D  \n",
       "2      303.399314  417.676998    D     D  \n",
       "3      316.002515  502.876430    D     D  \n",
       "4      269.091842  377.266730    D     D  \n",
       "...           ...         ...  ...   ...  \n",
       "49995  272.495833  433.128325    D     D  \n",
       "49996  297.987579  503.791602    E     D  \n",
       "49997  363.358205  439.075537    C     D  \n",
       "49998  339.248619  416.835122    E     C  \n",
       "49999  297.733136  427.241770    C     D  \n",
       "\n",
       "[49972 rows x 95 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "013b6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertCategoricalsToNumerics(df):\n",
    "    \n",
    "    categorical_fields = df.select_dtypes(include=['object'])\n",
    "    categorical_fields = categorical_fields.drop('class',axis=1)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col in categorical_fields.columns:\n",
    "                       \n",
    "            # Counting the different categories in the column\n",
    "            countOrdered_cats = list(dict(categorical_fields[col].value_counts()).keys()) # descending order\n",
    "            \n",
    "            \n",
    "            # Creating a list of numeric replacements\n",
    "            num_replacements = list(np.arange(len(countOrdered_cats))+1)\n",
    "            \n",
    "            # Dictionary of replacements to pass to df.replace()\n",
    "            replacements = dict(zip(countOrdered_cats, num_replacements))\n",
    "    \n",
    "            cd = df[col].replace(replacements, inplace=True)\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return df\n",
    "    \n",
    "train_numData = convertCategoricalsToNumerics(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26a9649",
   "metadata": {},
   "source": [
    "## Buidling ANN using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59b5941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68330a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_numData.loc[:, train_numData.columns != 'class']\n",
    "\n",
    "Y = train_numData.loc[:, train_numData.columns == 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6aba323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.20\n",
    "shuffle = True\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=test_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b299e073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39977, 94)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87edbadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_Y['class'])\n",
    "encoded_Y = encoder.transform(train_Y['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf0457c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49972"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55146d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "532522f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7fbeec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode 'class' values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_Y['class'])\n",
    "encoded_Y = encoder.transform(train_Y['class'])\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "onehot_Y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58219469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=94, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(100, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d64c00c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 01:53:06.831459: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-11 01:53:06.941141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-11 01:53:06.941736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1\n",
      "coreClock: 1.493GHz coreCount: 5 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2021-11-11 01:53:06.942026: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-11 01:53:06.942237: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2021-11-11 01:53:06.942391: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2021-11-11 01:53:06.954355: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-11 01:53:06.957436: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-11 01:53:06.957742: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-11-11 01:53:06.957937: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2021-11-11 01:53:06.958086: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-11-11 01:53:06.958106: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-11-11 01:53:06.959283: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-11 01:53:06.969359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-11 01:53:06.969399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "2021-11-11 01:53:07.738408: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-11 01:53:07.740756: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2799925000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "32/32 [==============================] - 29s 38ms/step - loss: 89061127.3939 - accuracy: 0.0125\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 588628.4413 - accuracy: 0.0127\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 32.7058 - accuracy: 0.0170\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 10.9863 - accuracy: 0.0169\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 9.8801 - accuracy: 0.0191\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 5.5709 - accuracy: 0.0201\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 5.2148 - accuracy: 0.0206\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 8.5834 - accuracy: 0.0216\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 5.3681 - accuracy: 0.0216\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 5.0392 - accuracy: 0.0203\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 5.1132 - accuracy: 0.0208\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.6556 - accuracy: 0.0210\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.6212 - accuracy: 0.0215\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.6026 - accuracy: 0.0219\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.6402 - accuracy: 0.0208\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.6184 - accuracy: 0.0216\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5964 - accuracy: 0.0207\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5887 - accuracy: 0.0203\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5813 - accuracy: 0.0208\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5882 - accuracy: 0.0210\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5793 - accuracy: 0.0198\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5809 - accuracy: 0.0221\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5876 - accuracy: 0.0212\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 4.5781 - accuracy: 0.0207\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5846 - accuracy: 0.0218\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5745 - accuracy: 0.0217\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5709 - accuracy: 0.0207\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5698 - accuracy: 0.0213\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5738 - accuracy: 0.0208\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5703 - accuracy: 0.0212\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5718 - accuracy: 0.0230\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5764 - accuracy: 0.0215\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5691 - accuracy: 0.0208\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5698 - accuracy: 0.0213\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5713 - accuracy: 0.0213\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5692 - accuracy: 0.0209\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5693 - accuracy: 0.0217\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5657 - accuracy: 0.0209\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5679 - accuracy: 0.0218\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5641 - accuracy: 0.0220\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5628 - accuracy: 0.0229\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5615 - accuracy: 0.0229\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5627 - accuracy: 0.0216\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5616 - accuracy: 0.0222\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 4.5612 - accuracy: 0.0230\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 4.5600 - accuracy: 0.0218\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5595 - accuracy: 0.0216\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5581 - accuracy: 0.0218\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5582 - accuracy: 0.0226\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5573 - accuracy: 0.0230\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5534 - accuracy: 0.0240\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5571 - accuracy: 0.0224\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5578 - accuracy: 0.0227\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5548 - accuracy: 0.0240\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5524 - accuracy: 0.0243\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5498 - accuracy: 0.0228\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5510 - accuracy: 0.0234\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5536 - accuracy: 0.0232\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5491 - accuracy: 0.0240\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5503 - accuracy: 0.0231\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5502 - accuracy: 0.0236\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5505 - accuracy: 0.0237\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5467 - accuracy: 0.0238\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5498 - accuracy: 0.0239\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5497 - accuracy: 0.0244\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5528 - accuracy: 0.0238\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5499 - accuracy: 0.0227\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 4.5480 - accuracy: 0.0254\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 4.5479 - accuracy: 0.0244\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.5459 - accuracy: 0.0251\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 4.5465 - accuracy: 0.0237\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.5480 - accuracy: 0.0237\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 2s 62ms/step - loss: 4.7085 - accuracy: 0.0231\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.5534 - accuracy: 0.0237\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5466 - accuracy: 0.0252\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 4.5478 - accuracy: 0.0237\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5404 - accuracy: 0.0260\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5439 - accuracy: 0.0243\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5415 - accuracy: 0.0240\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5364 - accuracy: 0.0263\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5337 - accuracy: 0.0272\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5333 - accuracy: 0.0250\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5382 - accuracy: 0.0278\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 4.5571 - accuracy: 0.0247\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5345 - accuracy: 0.0264\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5304 - accuracy: 0.0273\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5298 - accuracy: 0.0267\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5284 - accuracy: 0.0269\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5264 - accuracy: 0.0264\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5224 - accuracy: 0.0273\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5285 - accuracy: 0.0270\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5237 - accuracy: 0.0260\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5205 - accuracy: 0.0277\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5167 - accuracy: 0.0285\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5141 - accuracy: 0.0275\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5059 - accuracy: 0.0279\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.4999 - accuracy: 0.0277\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.4959 - accuracy: 0.0303\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.4909 - accuracy: 0.0305\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.4758 - accuracy: 0.0317\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.4635 - accuracy: 0.0331\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.4038 - accuracy: 0.0364\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.3816 - accuracy: 0.0427\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.3798 - accuracy: 0.0433\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.6552 - accuracy: 0.0380\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.3949 - accuracy: 0.0413\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 5.3444 - accuracy: 0.0426\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.9581 - accuracy: 0.0379\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.4807 - accuracy: 0.0355\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.3336 - accuracy: 0.0413\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.3096 - accuracy: 0.0412\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.3085 - accuracy: 0.0381\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.3160 - accuracy: 0.0376\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.2898 - accuracy: 0.0355\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.2776 - accuracy: 0.0405\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.2615 - accuracy: 0.0372\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.2592 - accuracy: 0.0361\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.2486 - accuracy: 0.0419\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 4.2623 - accuracy: 0.0463\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.2315 - accuracy: 0.0428\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.2241 - accuracy: 0.0392\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.2393 - accuracy: 0.0417\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.2278 - accuracy: 0.0435\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.2297 - accuracy: 0.0408\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 2s 52ms/step - loss: 4.2323 - accuracy: 0.0385\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.2187 - accuracy: 0.0436\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.2145 - accuracy: 0.0425\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.1985 - accuracy: 0.0437\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.2001 - accuracy: 0.0441\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.2037 - accuracy: 0.0441\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.1877 - accuracy: 0.0457\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.2008 - accuracy: 0.0434\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.2220 - accuracy: 0.0409\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.2003 - accuracy: 0.0445\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.1771 - accuracy: 0.0446\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.1775 - accuracy: 0.0457 0s - loss: 4.1750 - accu\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.1885 - accuracy: 0.0437\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.1654 - accuracy: 0.0485\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 4.1585 - accuracy: 0.0468\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.2056 - accuracy: 0.0445\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.1717 - accuracy: 0.0484\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.1910 - accuracy: 0.0474\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.2049 - accuracy: 0.0406\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.2056 - accuracy: 0.0439\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.1647 - accuracy: 0.0490\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.1916 - accuracy: 0.0450\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.2374 - accuracy: 0.0405\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.2205 - accuracy: 0.0432\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.1833 - accuracy: 0.0420\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.1694 - accuracy: 0.0457\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.1942 - accuracy: 0.0408\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.1659 - accuracy: 0.0461\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.1664 - accuracy: 0.0444\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.1623 - accuracy: 0.0422\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.1467 - accuracy: 0.0475\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.1486 - accuracy: 0.0474\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 4.1362 - accuracy: 0.0478\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.1548 - accuracy: 0.0469\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.1564 - accuracy: 0.0464\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.1455 - accuracy: 0.0491\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.1363 - accuracy: 0.0499\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 42ms/step - loss: 4.1515 - accuracy: 0.0500\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.1363 - accuracy: 0.0473\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.1479 - accuracy: 0.0460\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.1343 - accuracy: 0.0510\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.1291 - accuracy: 0.0454\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 4.1327 - accuracy: 0.0468\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.1323 - accuracy: 0.0531\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.1515 - accuracy: 0.0482\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.1253 - accuracy: 0.0513\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.1614 - accuracy: 0.0455\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.1486 - accuracy: 0.0454\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.1184 - accuracy: 0.0517\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.1772 - accuracy: 0.0455\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.1416 - accuracy: 0.0495\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 4.1188 - accuracy: 0.0483\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.1109 - accuracy: 0.0500\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.1229 - accuracy: 0.0531\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.1177 - accuracy: 0.0514\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.1334 - accuracy: 0.0471\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.1477 - accuracy: 0.0462\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.1109 - accuracy: 0.0520\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.1251 - accuracy: 0.0540 0s - los\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.1225 - accuracy: 0.0485\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.1167 - accuracy: 0.0520\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.1308 - accuracy: 0.0497\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.1024 - accuracy: 0.0560\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.1107 - accuracy: 0.0556\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.0986 - accuracy: 0.0530\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.1038 - accuracy: 0.0529\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.0991 - accuracy: 0.0522\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.1337 - accuracy: 0.0508\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.1096 - accuracy: 0.0532\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.1480 - accuracy: 0.0484\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 4.1008 - accuracy: 0.0537\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.0880 - accuracy: 0.0546\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.1028 - accuracy: 0.0541\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.0980 - accuracy: 0.0520 0s - loss:\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 4.0917 - accuracy: 0.0515\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.0972 - accuracy: 0.0544\n",
      "8/8 [==============================] - 1s 26ms/step - loss: 4.2092 - accuracy: 0.0443\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 4s 51ms/step - loss: 109430785.8182 - accuracy: 0.0139\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 11507.9629 - accuracy: 0.0135\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 13.7405 - accuracy: 0.0173\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 5.7373 - accuracy: 0.0199\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 9.5978 - accuracy: 0.0209\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 7.4066 - accuracy: 0.0194\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 8.8522 - accuracy: 0.0194\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 5.1412 - accuracy: 0.0191\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.6443 - accuracy: 0.0187\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.6421 - accuracy: 0.0202\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.6025 - accuracy: 0.0199\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.6004 - accuracy: 0.0194\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5965 - accuracy: 0.0201\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5925 - accuracy: 0.0195\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5900 - accuracy: 0.0194\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.5870 - accuracy: 0.0202\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5823 - accuracy: 0.0204\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5821 - accuracy: 0.0212\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5782 - accuracy: 0.0219\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5769 - accuracy: 0.0197\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5760 - accuracy: 0.0201\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5760 - accuracy: 0.0193\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5746 - accuracy: 0.0205\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5735 - accuracy: 0.0212\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5732 - accuracy: 0.0196\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5728 - accuracy: 0.0205\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5719 - accuracy: 0.0213\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5715 - accuracy: 0.0212\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5708 - accuracy: 0.0210\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5697 - accuracy: 0.0211\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5723 - accuracy: 0.0199\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5682 - accuracy: 0.0202\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 4.5684 - accuracy: 0.0211\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.5702 - accuracy: 0.0206\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 4.5700 - accuracy: 0.0217\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5721 - accuracy: 0.0212\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5683 - accuracy: 0.0208\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5686 - accuracy: 0.0212\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5692 - accuracy: 0.0211\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5692 - accuracy: 0.0208\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5669 - accuracy: 0.0216\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5675 - accuracy: 0.0221\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5682 - accuracy: 0.0208\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5675 - accuracy: 0.0227\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5695 - accuracy: 0.0211\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 4.5666 - accuracy: 0.0217\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 4.5680 - accuracy: 0.0204\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 4.5654 - accuracy: 0.0201\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5655 - accuracy: 0.0222\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.5671 - accuracy: 0.0206\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.5646 - accuracy: 0.0217\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 4.5650 - accuracy: 0.0208\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5667 - accuracy: 0.0215\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5655 - accuracy: 0.0215\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5647 - accuracy: 0.0226\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5636 - accuracy: 0.0214\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.5642 - accuracy: 0.0220\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5641 - accuracy: 0.0223\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5662 - accuracy: 0.0203\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5638 - accuracy: 0.0219\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5648 - accuracy: 0.0216\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5659 - accuracy: 0.0215\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5650 - accuracy: 0.0228\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5650 - accuracy: 0.0216\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5654 - accuracy: 0.0220\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5660 - accuracy: 0.0214\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5633 - accuracy: 0.0222\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5620 - accuracy: 0.0219\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5651 - accuracy: 0.0216\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5622 - accuracy: 0.0229\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5630 - accuracy: 0.0201\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5653 - accuracy: 0.0216\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5627 - accuracy: 0.0221\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5642 - accuracy: 0.0225\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.5649 - accuracy: 0.0211\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 4.5646 - accuracy: 0.0204\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5630 - accuracy: 0.0222\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5671 - accuracy: 0.0197\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5659 - accuracy: 0.0216\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5628 - accuracy: 0.0209\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5636 - accuracy: 0.0203\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5655 - accuracy: 0.0217\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5647 - accuracy: 0.0217\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5644 - accuracy: 0.0218\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5641 - accuracy: 0.0205\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5621 - accuracy: 0.0237\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5597 - accuracy: 0.0229\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.5635 - accuracy: 0.0225\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5617 - accuracy: 0.0217\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5636 - accuracy: 0.0215\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5630 - accuracy: 0.0209\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5629 - accuracy: 0.0212\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5633 - accuracy: 0.0227\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5652 - accuracy: 0.0220\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5642 - accuracy: 0.0230\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5636 - accuracy: 0.0211\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5627 - accuracy: 0.0217\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5625 - accuracy: 0.0229\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5618 - accuracy: 0.0217\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5692 - accuracy: 0.0215\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5714 - accuracy: 0.0218\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5696 - accuracy: 0.0208\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5757 - accuracy: 0.0207\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5642 - accuracy: 0.0215\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5590 - accuracy: 0.0230\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5611 - accuracy: 0.0218\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5640 - accuracy: 0.0220\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5640 - accuracy: 0.0211\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5599 - accuracy: 0.0222\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5601 - accuracy: 0.0214\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5578 - accuracy: 0.0226\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5513 - accuracy: 0.0262\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5508 - accuracy: 0.0271\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5312 - accuracy: 0.0314\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5348 - accuracy: 0.0294\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5301 - accuracy: 0.0305\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5189 - accuracy: 0.0316\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5097 - accuracy: 0.0332\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 4.5053 - accuracy: 0.0333\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.4991 - accuracy: 0.0319\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.4942 - accuracy: 0.0320\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 44ms/step - loss: 4.4924 - accuracy: 0.0331\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.4827 - accuracy: 0.0367\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.4924 - accuracy: 0.0338\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.4746 - accuracy: 0.0369\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.4598 - accuracy: 0.0397\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 4.4452 - accuracy: 0.0403\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.4377 - accuracy: 0.0391\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.4390 - accuracy: 0.0398\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.4215 - accuracy: 0.0398\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.4249 - accuracy: 0.0409\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 4.4125 - accuracy: 0.0410\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.4050 - accuracy: 0.0432\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.4053 - accuracy: 0.0436\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.4015 - accuracy: 0.0446\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.3970 - accuracy: 0.0428\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.3773 - accuracy: 0.0447\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.3749 - accuracy: 0.0463\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.3696 - accuracy: 0.0466\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 4.3791 - accuracy: 0.0451\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.3686 - accuracy: 0.0476\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.3645 - accuracy: 0.0467\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.3641 - accuracy: 0.0493\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.3609 - accuracy: 0.0478\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.3519 - accuracy: 0.0474\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.3550 - accuracy: 0.0464\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.3538 - accuracy: 0.0486\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.3669 - accuracy: 0.0464\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.3537 - accuracy: 0.0478\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.3498 - accuracy: 0.0498\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.3391 - accuracy: 0.0506\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.3496 - accuracy: 0.0475\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.3387 - accuracy: 0.0480\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.3344 - accuracy: 0.0492\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.3314 - accuracy: 0.0504\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.3326 - accuracy: 0.0494\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.3413 - accuracy: 0.0489\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.3335 - accuracy: 0.0471\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.3289 - accuracy: 0.0490\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.3343 - accuracy: 0.0512\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.3128 - accuracy: 0.0511\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 4.3249 - accuracy: 0.0480\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.3222 - accuracy: 0.0489\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.3178 - accuracy: 0.0503\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.3134 - accuracy: 0.0526\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.3171 - accuracy: 0.0484\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.3129 - accuracy: 0.0512\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.3194 - accuracy: 0.0499\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.3005 - accuracy: 0.0515\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.3074 - accuracy: 0.0488\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.3067 - accuracy: 0.0497\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.3342 - accuracy: 0.0511\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 5.5362 - accuracy: 0.0464\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5486 - accuracy: 0.0402\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.3975 - accuracy: 0.0421\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.3595 - accuracy: 0.0479\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 2s 46ms/step - loss: 4.5650 - accuracy: 0.0453\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 6.9485 - accuracy: 0.0400\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.4610 - accuracy: 0.0413\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.3778 - accuracy: 0.0442\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.3690 - accuracy: 0.0453\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.3586 - accuracy: 0.0443\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.3490 - accuracy: 0.0450\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.3554 - accuracy: 0.0493\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.3547 - accuracy: 0.0448\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.3403 - accuracy: 0.0504\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.3470 - accuracy: 0.0485\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.3371 - accuracy: 0.0498\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.3408 - accuracy: 0.0503\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.3293 - accuracy: 0.0479\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.3327 - accuracy: 0.0498\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.3290 - accuracy: 0.0506\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.3171 - accuracy: 0.0514\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.3209 - accuracy: 0.0496\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.3241 - accuracy: 0.0483\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.3308 - accuracy: 0.0492\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 4.3206 - accuracy: 0.0520\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.3132 - accuracy: 0.0483\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.3034 - accuracy: 0.0523\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 4.3084 - accuracy: 0.0508\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 4.3789 - accuracy: 0.0518\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 45ms/step - loss: 123223662.7879 - accuracy: 0.0165\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 69824.1839 - accuracy: 0.0123\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 107.2497 - accuracy: 0.0134\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 33.6693 - accuracy: 0.0181\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 15.8169 - accuracy: 0.0202\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 14.3336 - accuracy: 0.0203\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 5.9095 - accuracy: 0.0195\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 5.6390 - accuracy: 0.0210\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 5.1798 - accuracy: 0.0218\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 5.0323 - accuracy: 0.0208\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 5.2259 - accuracy: 0.0211\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 5.8224 - accuracy: 0.0206\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 19.1362 - accuracy: 0.0219\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 59.9677 - accuracy: 0.0210\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 5.0052 - accuracy: 0.0215\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.8709 - accuracy: 0.0208\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.6887 - accuracy: 0.0204\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.7010 - accuracy: 0.0217\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 4.7368 - accuracy: 0.0211\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.8110 - accuracy: 0.0209\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.7092 - accuracy: 0.0209\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.6682 - accuracy: 0.0205\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.6563 - accuracy: 0.0218\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.6169 - accuracy: 0.0217\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.6067 - accuracy: 0.0219\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5963 - accuracy: 0.0213\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5892 - accuracy: 0.0223\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5730 - accuracy: 0.0221\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5759 - accuracy: 0.0202\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5708 - accuracy: 0.0224\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5713 - accuracy: 0.0216\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5741 - accuracy: 0.0222\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.6165 - accuracy: 0.0222\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.7420 - accuracy: 0.0232\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5977 - accuracy: 0.0218\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5917 - accuracy: 0.0218\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.6733 - accuracy: 0.0224\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.6093 - accuracy: 0.0223\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5575 - accuracy: 0.0233\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5581 - accuracy: 0.0231\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5625 - accuracy: 0.0216\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5596 - accuracy: 0.0227\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5606 - accuracy: 0.0216\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5564 - accuracy: 0.0241\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5611 - accuracy: 0.0215\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5602 - accuracy: 0.0220\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5537 - accuracy: 0.0243\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 4.5583 - accuracy: 0.0215\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5579 - accuracy: 0.0231\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5598 - accuracy: 0.0210\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 4.5581 - accuracy: 0.0222\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5579 - accuracy: 0.0232\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5562 - accuracy: 0.0231\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5547 - accuracy: 0.0233\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5547 - accuracy: 0.0235\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5566 - accuracy: 0.0234\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5515 - accuracy: 0.0231\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5538 - accuracy: 0.0214 1s - loss: 4.5568 - accuracy:  - ETA: 1s -\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5547 - accuracy: 0.0234\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5574 - accuracy: 0.0208\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5532 - accuracy: 0.0239\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5538 - accuracy: 0.0234\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5569 - accuracy: 0.0223\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5557 - accuracy: 0.0229\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5531 - accuracy: 0.0229\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5519 - accuracy: 0.0223\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5542 - accuracy: 0.0221\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5522 - accuracy: 0.0226\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5549 - accuracy: 0.0222\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.5482 - accuracy: 0.0242\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.5536 - accuracy: 0.0236\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.5535 - accuracy: 0.0229\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5546 - accuracy: 0.0224\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5533 - accuracy: 0.0234\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5529 - accuracy: 0.0231\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5527 - accuracy: 0.0244\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5504 - accuracy: 0.0228\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 4.5530 - accuracy: 0.0242\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5537 - accuracy: 0.0230\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 4.5552 - accuracy: 0.0219\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5506 - accuracy: 0.0230\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5482 - accuracy: 0.0241\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5530 - accuracy: 0.0228\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5532 - accuracy: 0.0242\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5533 - accuracy: 0.0228\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5530 - accuracy: 0.0230\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5520 - accuracy: 0.0232\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5539 - accuracy: 0.0228\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5492 - accuracy: 0.0235\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5527 - accuracy: 0.0231\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5524 - accuracy: 0.0228\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5519 - accuracy: 0.0232\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5499 - accuracy: 0.0246\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5496 - accuracy: 0.0237\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5533 - accuracy: 0.0223\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5501 - accuracy: 0.0232\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5512 - accuracy: 0.0237\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5534 - accuracy: 0.0235\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5528 - accuracy: 0.0230\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5515 - accuracy: 0.0237\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5507 - accuracy: 0.0236\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5548 - accuracy: 0.0225\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5522 - accuracy: 0.0220\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5509 - accuracy: 0.0234\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5528 - accuracy: 0.0223\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.5550 - accuracy: 0.0237\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 2s 52ms/step - loss: 4.5489 - accuracy: 0.0240\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 2s 52ms/step - loss: 4.5530 - accuracy: 0.0229\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.5542 - accuracy: 0.0225\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.5500 - accuracy: 0.0248\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.5503 - accuracy: 0.0241\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.5528 - accuracy: 0.0234\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.5539 - accuracy: 0.0224\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5522 - accuracy: 0.0233\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.5512 - accuracy: 0.0236\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5515 - accuracy: 0.0218\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5542 - accuracy: 0.0226\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5521 - accuracy: 0.0227\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5521 - accuracy: 0.0241\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5584 - accuracy: 0.0231\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5517 - accuracy: 0.0231\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5507 - accuracy: 0.0243\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5538 - accuracy: 0.0229\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5496 - accuracy: 0.0242\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 4.5517 - accuracy: 0.0242\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5516 - accuracy: 0.0226\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 4.5540 - accuracy: 0.0227\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 4.5514 - accuracy: 0.0233\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5478 - accuracy: 0.0237\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5476 - accuracy: 0.0245\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 2s 52ms/step - loss: 4.5508 - accuracy: 0.0257\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5482 - accuracy: 0.0242\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5508 - accuracy: 0.0239 0s - loss: 4.5\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5544 - accuracy: 0.0225\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5483 - accuracy: 0.0245\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5493 - accuracy: 0.0234\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5462 - accuracy: 0.0240\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5475 - accuracy: 0.0238\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5469 - accuracy: 0.0243\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 4.5469 - accuracy: 0.0251\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5482 - accuracy: 0.0241\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5533 - accuracy: 0.0229\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 4.5516 - accuracy: 0.0232\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 4.5492 - accuracy: 0.0243\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 2s 63ms/step - loss: 4.5492 - accuracy: 0.0253\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5515 - accuracy: 0.0249\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5487 - accuracy: 0.0236\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5468 - accuracy: 0.0234\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5512 - accuracy: 0.0243\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5529 - accuracy: 0.0246\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5532 - accuracy: 0.0242\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5513 - accuracy: 0.0241\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5498 - accuracy: 0.0230\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5479 - accuracy: 0.0245\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5491 - accuracy: 0.0245\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5497 - accuracy: 0.0233\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5532 - accuracy: 0.0228\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5555 - accuracy: 0.0219\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 4.5487 - accuracy: 0.0234\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 4.5459 - accuracy: 0.0244\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5518 - accuracy: 0.0234\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5493 - accuracy: 0.0244\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5522 - accuracy: 0.0232\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5506 - accuracy: 0.0240\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 4.5505 - accuracy: 0.0240\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5480 - accuracy: 0.0246\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5441 - accuracy: 0.0254\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5519 - accuracy: 0.0227\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5451 - accuracy: 0.0237\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5427 - accuracy: 0.0246\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5452 - accuracy: 0.0254\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5469 - accuracy: 0.0241\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5442 - accuracy: 0.0238\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5432 - accuracy: 0.0251\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5486 - accuracy: 0.0240\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5460 - accuracy: 0.0246\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5462 - accuracy: 0.0247\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5474 - accuracy: 0.0237\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 2s 52ms/step - loss: 4.5452 - accuracy: 0.0244 0s - loss: 4.5453 - \n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 2s 65ms/step - loss: 4.5451 - accuracy: 0.0248\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 2s 65ms/step - loss: 4.5444 - accuracy: 0.0243\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 4.5444 - accuracy: 0.0258\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5446 - accuracy: 0.0252\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5442 - accuracy: 0.0245\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5462 - accuracy: 0.0255\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5460 - accuracy: 0.0244\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 4.5443 - accuracy: 0.0250\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5441 - accuracy: 0.0261\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5448 - accuracy: 0.0256\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 4.5456 - accuracy: 0.0247\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5453 - accuracy: 0.0236\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5416 - accuracy: 0.0247\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5417 - accuracy: 0.0258\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 4.5409 - accuracy: 0.0251\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 4.5434 - accuracy: 0.0261\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5419 - accuracy: 0.0256\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5437 - accuracy: 0.0251\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5431 - accuracy: 0.0259\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5476 - accuracy: 0.0248\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5410 - accuracy: 0.0256\n",
      "8/8 [==============================] - 1s 18ms/step - loss: 4.6633 - accuracy: 0.0253\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 3s 38ms/step - loss: 90617583.1515 - accuracy: 0.0104\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 64970.7174 - accuracy: 0.0094\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 79.2881 - accuracy: 0.0138\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 17.2936 - accuracy: 0.0199\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 5.1545 - accuracy: 0.0214\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 5.0436 - accuracy: 0.0220\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.8169 - accuracy: 0.0219 1s - l\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.7182 - accuracy: 0.0208\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 4.6504 - accuracy: 0.0227\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.6763 - accuracy: 0.0220\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.7648 - accuracy: 0.0210\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.6391 - accuracy: 0.0206\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.6220 - accuracy: 0.0214\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.5965 - accuracy: 0.0209\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 4.5914 - accuracy: 0.0203\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5910 - accuracy: 0.0224\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 4.5842 - accuracy: 0.0216\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5813 - accuracy: 0.0217\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5801 - accuracy: 0.0216\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5791 - accuracy: 0.0216\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5751 - accuracy: 0.0226\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5737 - accuracy: 0.0221\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5720 - accuracy: 0.0226\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5686 - accuracy: 0.0218\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5683 - accuracy: 0.0219\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5678 - accuracy: 0.0212\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5677 - accuracy: 0.0218\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5657 - accuracy: 0.0217\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5646 - accuracy: 0.0222\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5621 - accuracy: 0.0221\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5684 - accuracy: 0.0217\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5646 - accuracy: 0.0227\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5683 - accuracy: 0.0219\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5765 - accuracy: 0.0219\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5661 - accuracy: 0.0221\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5654 - accuracy: 0.0220\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 4.5640 - accuracy: 0.0221\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5627 - accuracy: 0.0221\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5609 - accuracy: 0.0216\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5623 - accuracy: 0.0215\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5621 - accuracy: 0.0213\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5663 - accuracy: 0.0223\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5646 - accuracy: 0.0229\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5644 - accuracy: 0.0233\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5583 - accuracy: 0.0250\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5612 - accuracy: 0.0230\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5634 - accuracy: 0.0224\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5591 - accuracy: 0.0243\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.5619 - accuracy: 0.0221\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.5628 - accuracy: 0.0218\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5635 - accuracy: 0.0212\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5621 - accuracy: 0.0217\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 4.5612 - accuracy: 0.0225\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 4.5619 - accuracy: 0.0222\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 2s 52ms/step - loss: 4.5609 - accuracy: 0.0219\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.5628 - accuracy: 0.0224\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.5595 - accuracy: 0.0229\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 4.5598 - accuracy: 0.0217\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 4.5598 - accuracy: 0.0216\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 4.5609 - accuracy: 0.0227\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5601 - accuracy: 0.0227\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5574 - accuracy: 0.0231\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5609 - accuracy: 0.0223\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5598 - accuracy: 0.0222\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5597 - accuracy: 0.0230\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5607 - accuracy: 0.0227\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5621 - accuracy: 0.0217\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5571 - accuracy: 0.0231\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5603 - accuracy: 0.0220\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5605 - accuracy: 0.0224\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5577 - accuracy: 0.0239\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5609 - accuracy: 0.0220\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5589 - accuracy: 0.0222\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5533 - accuracy: 0.0240\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5601 - accuracy: 0.0228\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5628 - accuracy: 0.0227\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5585 - accuracy: 0.0230\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5633 - accuracy: 0.0212\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5614 - accuracy: 0.0232\n",
      "Epoch 80/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5590 - accuracy: 0.0220\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5554 - accuracy: 0.0233\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5579 - accuracy: 0.0229\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5597 - accuracy: 0.0230\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5607 - accuracy: 0.0225\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5608 - accuracy: 0.0234\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5590 - accuracy: 0.0216\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5591 - accuracy: 0.0213\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5573 - accuracy: 0.0234\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5617 - accuracy: 0.0223\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 2s 52ms/step - loss: 4.5613 - accuracy: 0.0214\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5574 - accuracy: 0.0236\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 4.5571 - accuracy: 0.0225\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5587 - accuracy: 0.0217\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5578 - accuracy: 0.0211 0s - loss: 4.5575 - ac\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5566 - accuracy: 0.0229\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 4.5571 - accuracy: 0.0210\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5573 - accuracy: 0.0227\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 4.5574 - accuracy: 0.0226\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5577 - accuracy: 0.0232\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 2s 51ms/step - loss: 4.5585 - accuracy: 0.0231\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5592 - accuracy: 0.0228\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5636 - accuracy: 0.0221\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 8.7523 - accuracy: 0.0231\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 10.4177 - accuracy: 0.0217\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 2423188.8790 - accuracy: 0.0210\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.8964 - accuracy: 0.0214\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5619 - accuracy: 0.0209\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5632 - accuracy: 0.0214\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5637 - accuracy: 0.0227\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5640 - accuracy: 0.0211\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5651 - accuracy: 0.0228\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5656 - accuracy: 0.0219\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5649 - accuracy: 0.0229\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5673 - accuracy: 0.0215\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5633 - accuracy: 0.0229\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5642 - accuracy: 0.0225\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5649 - accuracy: 0.0209\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5668 - accuracy: 0.0219\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5623 - accuracy: 0.0211\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5609 - accuracy: 0.0222\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5629 - accuracy: 0.0207\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5656 - accuracy: 0.0214\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5649 - accuracy: 0.0205\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5666 - accuracy: 0.0218\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5619 - accuracy: 0.0217\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5640 - accuracy: 0.0201\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5645 - accuracy: 0.0223\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.5661 - accuracy: 0.0212\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5650 - accuracy: 0.0207\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5639 - accuracy: 0.0225\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5635 - accuracy: 0.0216\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5641 - accuracy: 0.0219\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5665 - accuracy: 0.0211\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 4.5650 - accuracy: 0.0214\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5640 - accuracy: 0.0209\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 4.5654 - accuracy: 0.0217\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5633 - accuracy: 0.0221\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5647 - accuracy: 0.0209\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5633 - accuracy: 0.0218\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.5625 - accuracy: 0.0220\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5666 - accuracy: 0.0218\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5622 - accuracy: 0.0232\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5614 - accuracy: 0.0227\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5638 - accuracy: 0.0208\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 4.5656 - accuracy: 0.0226\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5659 - accuracy: 0.0206\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5637 - accuracy: 0.0228\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5671 - accuracy: 0.0202\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5639 - accuracy: 0.0217\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.5655 - accuracy: 0.0215\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5626 - accuracy: 0.0218\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5630 - accuracy: 0.0223\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5637 - accuracy: 0.0220\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5653 - accuracy: 0.0204\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5654 - accuracy: 0.0214\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5636 - accuracy: 0.0216\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5641 - accuracy: 0.0215\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5656 - accuracy: 0.0217\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5635 - accuracy: 0.0219\n",
      "Epoch 160/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5651 - accuracy: 0.0210\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5665 - accuracy: 0.0224\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5625 - accuracy: 0.0227\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.5683 - accuracy: 0.0203\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5664 - accuracy: 0.0204\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5628 - accuracy: 0.0219\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5632 - accuracy: 0.0208\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5643 - accuracy: 0.0217\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5649 - accuracy: 0.0221\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5627 - accuracy: 0.0223\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.5649 - accuracy: 0.0226\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.5650 - accuracy: 0.0214\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5635 - accuracy: 0.0228\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5639 - accuracy: 0.0214\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5630 - accuracy: 0.0221\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5639 - accuracy: 0.0231\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5652 - accuracy: 0.0222\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5641 - accuracy: 0.0209\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5655 - accuracy: 0.0213\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5633 - accuracy: 0.0201\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5624 - accuracy: 0.0216\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5651 - accuracy: 0.0211\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5645 - accuracy: 0.0217\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5638 - accuracy: 0.0223\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5657 - accuracy: 0.0209\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5655 - accuracy: 0.0217\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5637 - accuracy: 0.0216\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5644 - accuracy: 0.0218 1s -\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.5645 - accuracy: 0.0218\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5651 - accuracy: 0.0211\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5653 - accuracy: 0.0223\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5622 - accuracy: 0.0233\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5649 - accuracy: 0.0228\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.5666 - accuracy: 0.0204\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5617 - accuracy: 0.0222\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5663 - accuracy: 0.0210\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5656 - accuracy: 0.0219\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5679 - accuracy: 0.0226\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5640 - accuracy: 0.0216\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5647 - accuracy: 0.0214\n",
      "Epoch 200/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 2s 47ms/step - loss: 4.5661 - accuracy: 0.0206\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 4.5743 - accuracy: 0.0176\n",
      "Epoch 1/200\n",
      "32/32 [==============================] - 3s 40ms/step - loss: 127348894.7879 - accuracy: 0.0101\n",
      "Epoch 2/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 19062349.3030 - accuracy: 0.0111\n",
      "Epoch 3/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 3515050.8030 - accuracy: 0.0181\n",
      "Epoch 4/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 931282.7472 - accuracy: 0.0192\n",
      "Epoch 5/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 326.1629 - accuracy: 0.0233\n",
      "Epoch 6/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 12048.0524 - accuracy: 0.0238\n",
      "Epoch 7/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 12.5307 - accuracy: 0.0195\n",
      "Epoch 8/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 7.3482 - accuracy: 0.0168\n",
      "Epoch 9/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 7.2693 - accuracy: 0.0174\n",
      "Epoch 10/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 5.1535 - accuracy: 0.0188\n",
      "Epoch 11/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 5.3307 - accuracy: 0.0195\n",
      "Epoch 12/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.7534 - accuracy: 0.0197\n",
      "Epoch 13/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.6731 - accuracy: 0.0203\n",
      "Epoch 14/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.6179 - accuracy: 0.0192\n",
      "Epoch 15/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5972 - accuracy: 0.0197\n",
      "Epoch 16/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5839 - accuracy: 0.0193\n",
      "Epoch 17/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5898 - accuracy: 0.0202\n",
      "Epoch 18/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.5899 - accuracy: 0.0193\n",
      "Epoch 19/200\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 4.5784 - accuracy: 0.0191\n",
      "Epoch 20/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5812 - accuracy: 0.0196\n",
      "Epoch 21/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5711 - accuracy: 0.0189\n",
      "Epoch 22/200\n",
      "32/32 [==============================] - 1s 32ms/step - loss: 4.5719 - accuracy: 0.0201\n",
      "Epoch 23/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5687 - accuracy: 0.0203\n",
      "Epoch 24/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5673 - accuracy: 0.0236\n",
      "Epoch 25/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.5705 - accuracy: 0.0251\n",
      "Epoch 26/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5649 - accuracy: 0.0246\n",
      "Epoch 27/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5601 - accuracy: 0.0261\n",
      "Epoch 28/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5594 - accuracy: 0.0260\n",
      "Epoch 29/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.5540 - accuracy: 0.0249\n",
      "Epoch 30/200\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 4.5483 - accuracy: 0.0271\n",
      "Epoch 31/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.5514 - accuracy: 0.0254\n",
      "Epoch 32/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5444 - accuracy: 0.0254\n",
      "Epoch 33/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.5434 - accuracy: 0.0257\n",
      "Epoch 34/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.5380 - accuracy: 0.0271\n",
      "Epoch 35/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.5341 - accuracy: 0.0261\n",
      "Epoch 36/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.5311 - accuracy: 0.0268\n",
      "Epoch 37/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5586 - accuracy: 0.0271\n",
      "Epoch 38/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.5508 - accuracy: 0.0273\n",
      "Epoch 39/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5236 - accuracy: 0.0287\n",
      "Epoch 40/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5259 - accuracy: 0.0277\n",
      "Epoch 41/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 5.2401 - accuracy: 0.0299\n",
      "Epoch 42/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 6.0402 - accuracy: 0.0247\n",
      "Epoch 43/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 6.9839 - accuracy: 0.0268\n",
      "Epoch 44/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.6941 - accuracy: 0.0282\n",
      "Epoch 45/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.4885 - accuracy: 0.0342\n",
      "Epoch 46/200\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 4.4398 - accuracy: 0.0381\n",
      "Epoch 47/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.4069 - accuracy: 0.0390\n",
      "Epoch 48/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.3950 - accuracy: 0.0388\n",
      "Epoch 49/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.3624 - accuracy: 0.0388\n",
      "Epoch 50/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.3430 - accuracy: 0.0396\n",
      "Epoch 51/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.4631 - accuracy: 0.0395\n",
      "Epoch 52/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.3867 - accuracy: 0.0351\n",
      "Epoch 53/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.3180 - accuracy: 0.0382\n",
      "Epoch 54/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.3025 - accuracy: 0.0389\n",
      "Epoch 55/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.2895 - accuracy: 0.0386\n",
      "Epoch 56/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.2775 - accuracy: 0.0378\n",
      "Epoch 57/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.2684 - accuracy: 0.0383\n",
      "Epoch 58/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.2640 - accuracy: 0.0383\n",
      "Epoch 59/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.2585 - accuracy: 0.0366\n",
      "Epoch 60/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 4.2531 - accuracy: 0.0343\n",
      "Epoch 61/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.2389 - accuracy: 0.0366\n",
      "Epoch 62/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.2434 - accuracy: 0.0378\n",
      "Epoch 63/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.2345 - accuracy: 0.0395\n",
      "Epoch 64/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.2295 - accuracy: 0.0406\n",
      "Epoch 65/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.2239 - accuracy: 0.0393\n",
      "Epoch 66/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.2237 - accuracy: 0.0403\n",
      "Epoch 67/200\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 4.2123 - accuracy: 0.0390\n",
      "Epoch 68/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.2204 - accuracy: 0.0405\n",
      "Epoch 69/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 4.2123 - accuracy: 0.0401\n",
      "Epoch 70/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 4.2072 - accuracy: 0.0405\n",
      "Epoch 71/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.2057 - accuracy: 0.0416\n",
      "Epoch 72/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.2019 - accuracy: 0.0422\n",
      "Epoch 73/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.1958 - accuracy: 0.0445\n",
      "Epoch 74/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.1927 - accuracy: 0.0411\n",
      "Epoch 75/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.1884 - accuracy: 0.0433\n",
      "Epoch 76/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.1910 - accuracy: 0.0436\n",
      "Epoch 77/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.1863 - accuracy: 0.0440\n",
      "Epoch 78/200\n",
      "32/32 [==============================] - 2s 52ms/step - loss: 4.1806 - accuracy: 0.0429\n",
      "Epoch 79/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.1832 - accuracy: 0.0434\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 44ms/step - loss: 4.1761 - accuracy: 0.0436\n",
      "Epoch 81/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.1754 - accuracy: 0.0453\n",
      "Epoch 82/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.1685 - accuracy: 0.0445\n",
      "Epoch 83/200\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 4.1728 - accuracy: 0.0433\n",
      "Epoch 84/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.1622 - accuracy: 0.0466\n",
      "Epoch 85/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.1556 - accuracy: 0.0466\n",
      "Epoch 86/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.1456 - accuracy: 0.0480\n",
      "Epoch 87/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.1365 - accuracy: 0.0506\n",
      "Epoch 88/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.1366 - accuracy: 0.0471\n",
      "Epoch 89/200\n",
      "32/32 [==============================] - 2s 49ms/step - loss: 4.1303 - accuracy: 0.0494\n",
      "Epoch 90/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.1425 - accuracy: 0.0480\n",
      "Epoch 91/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 4.1313 - accuracy: 0.0503\n",
      "Epoch 92/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.1248 - accuracy: 0.0478\n",
      "Epoch 93/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.1364 - accuracy: 0.0467\n",
      "Epoch 94/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.1416 - accuracy: 0.0507\n",
      "Epoch 95/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.1147 - accuracy: 0.0522\n",
      "Epoch 96/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.1227 - accuracy: 0.0490\n",
      "Epoch 97/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.1049 - accuracy: 0.0502\n",
      "Epoch 98/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.0949 - accuracy: 0.0543\n",
      "Epoch 99/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.0954 - accuracy: 0.0548\n",
      "Epoch 100/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.1065 - accuracy: 0.0508\n",
      "Epoch 101/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.0929 - accuracy: 0.0519\n",
      "Epoch 102/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.0841 - accuracy: 0.0524\n",
      "Epoch 103/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.0993 - accuracy: 0.0530\n",
      "Epoch 104/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.1007 - accuracy: 0.0503\n",
      "Epoch 105/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.0732 - accuracy: 0.0557\n",
      "Epoch 106/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.0697 - accuracy: 0.0575\n",
      "Epoch 107/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.0862 - accuracy: 0.0534\n",
      "Epoch 108/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.0928 - accuracy: 0.0527\n",
      "Epoch 109/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.0733 - accuracy: 0.0572\n",
      "Epoch 110/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.0654 - accuracy: 0.0549\n",
      "Epoch 111/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.0547 - accuracy: 0.0557\n",
      "Epoch 112/200\n",
      "32/32 [==============================] - 1s 31ms/step - loss: 4.0616 - accuracy: 0.0526\n",
      "Epoch 113/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.0705 - accuracy: 0.0556\n",
      "Epoch 114/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.0672 - accuracy: 0.0553\n",
      "Epoch 115/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.1231 - accuracy: 0.0481\n",
      "Epoch 116/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.0882 - accuracy: 0.0512\n",
      "Epoch 117/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.0613 - accuracy: 0.0514\n",
      "Epoch 118/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.0510 - accuracy: 0.0579\n",
      "Epoch 119/200\n",
      "32/32 [==============================] - 1s 33ms/step - loss: 4.0504 - accuracy: 0.0569\n",
      "Epoch 120/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.0757 - accuracy: 0.0527\n",
      "Epoch 121/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.7645 - accuracy: 0.0472\n",
      "Epoch 122/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 5.2068 - accuracy: 0.0467\n",
      "Epoch 123/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.1367 - accuracy: 0.0474\n",
      "Epoch 124/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.5698 - accuracy: 0.0453\n",
      "Epoch 125/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.2064 - accuracy: 0.0414\n",
      "Epoch 126/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.1604 - accuracy: 0.0447\n",
      "Epoch 127/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.1424 - accuracy: 0.0453\n",
      "Epoch 128/200\n",
      "32/32 [==============================] - 1s 47ms/step - loss: 4.1086 - accuracy: 0.0476\n",
      "Epoch 129/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.0955 - accuracy: 0.0537\n",
      "Epoch 130/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.1015 - accuracy: 0.0526\n",
      "Epoch 131/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.0951 - accuracy: 0.0494\n",
      "Epoch 132/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.1462 - accuracy: 0.0502\n",
      "Epoch 133/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.0841 - accuracy: 0.0506\n",
      "Epoch 134/200\n",
      "32/32 [==============================] - 1s 35ms/step - loss: 4.0693 - accuracy: 0.0532\n",
      "Epoch 135/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.0764 - accuracy: 0.0517\n",
      "Epoch 136/200\n",
      "32/32 [==============================] - 2s 50ms/step - loss: 4.0629 - accuracy: 0.0545\n",
      "Epoch 137/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.0566 - accuracy: 0.0558\n",
      "Epoch 138/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.0518 - accuracy: 0.0541\n",
      "Epoch 139/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.0695 - accuracy: 0.0567\n",
      "Epoch 140/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.0204 - accuracy: 0.0639\n",
      "Epoch 141/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.0246 - accuracy: 0.0612\n",
      "Epoch 142/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.0283 - accuracy: 0.0551\n",
      "Epoch 143/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 4.0149 - accuracy: 0.0586\n",
      "Epoch 144/200\n",
      "32/32 [==============================] - 1s 46ms/step - loss: 4.0162 - accuracy: 0.0582\n",
      "Epoch 145/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.0218 - accuracy: 0.0594\n",
      "Epoch 146/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.0129 - accuracy: 0.0598\n",
      "Epoch 147/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.0033 - accuracy: 0.0600\n",
      "Epoch 148/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.1494 - accuracy: 0.0463\n",
      "Epoch 149/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.0539 - accuracy: 0.0519\n",
      "Epoch 150/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.0479 - accuracy: 0.0496\n",
      "Epoch 151/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.0690 - accuracy: 0.0504\n",
      "Epoch 152/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.0627 - accuracy: 0.0530\n",
      "Epoch 153/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.0442 - accuracy: 0.0578\n",
      "Epoch 154/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.0269 - accuracy: 0.0547\n",
      "Epoch 155/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 4.0032 - accuracy: 0.0576\n",
      "Epoch 156/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.0094 - accuracy: 0.0605\n",
      "Epoch 157/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.1220 - accuracy: 0.0520\n",
      "Epoch 158/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.1180 - accuracy: 0.0462\n",
      "Epoch 159/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.0795 - accuracy: 0.0509\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 40ms/step - loss: 4.1228 - accuracy: 0.0431\n",
      "Epoch 161/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 4.1129 - accuracy: 0.0511\n",
      "Epoch 162/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.1377 - accuracy: 0.0448\n",
      "Epoch 163/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.0843 - accuracy: 0.0466\n",
      "Epoch 164/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.0568 - accuracy: 0.0550\n",
      "Epoch 165/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.0498 - accuracy: 0.0541\n",
      "Epoch 166/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.0713 - accuracy: 0.0520\n",
      "Epoch 167/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.0462 - accuracy: 0.0533\n",
      "Epoch 168/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.0734 - accuracy: 0.0533\n",
      "Epoch 169/200\n",
      "32/32 [==============================] - 2s 47ms/step - loss: 4.0270 - accuracy: 0.0556\n",
      "Epoch 170/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.0155 - accuracy: 0.0587\n",
      "Epoch 171/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.0143 - accuracy: 0.0565\n",
      "Epoch 172/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 3.9860 - accuracy: 0.0666\n",
      "Epoch 173/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 3.9918 - accuracy: 0.0603\n",
      "Epoch 174/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 3.9966 - accuracy: 0.0633\n",
      "Epoch 175/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.0231 - accuracy: 0.0631\n",
      "Epoch 176/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.0101 - accuracy: 0.0573\n",
      "Epoch 177/200\n",
      "32/32 [==============================] - 1s 34ms/step - loss: 3.9840 - accuracy: 0.0665\n",
      "Epoch 178/200\n",
      "32/32 [==============================] - 1s 45ms/step - loss: 3.9890 - accuracy: 0.0639\n",
      "Epoch 179/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 3.9837 - accuracy: 0.0595\n",
      "Epoch 180/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 3.9884 - accuracy: 0.0628\n",
      "Epoch 181/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.0614 - accuracy: 0.0556\n",
      "Epoch 182/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.0152 - accuracy: 0.0606\n",
      "Epoch 183/200\n",
      "32/32 [==============================] - 1s 37ms/step - loss: 4.0236 - accuracy: 0.0601\n",
      "Epoch 184/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.0071 - accuracy: 0.0606\n",
      "Epoch 185/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 3.9860 - accuracy: 0.0636\n",
      "Epoch 186/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 4.0005 - accuracy: 0.0593\n",
      "Epoch 187/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 4.1981 - accuracy: 0.0476\n",
      "Epoch 188/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.1645 - accuracy: 0.0471\n",
      "Epoch 189/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.1495 - accuracy: 0.0546\n",
      "Epoch 190/200\n",
      "32/32 [==============================] - 1s 39ms/step - loss: 4.0743 - accuracy: 0.0532\n",
      "Epoch 191/200\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 4.0347 - accuracy: 0.0606\n",
      "Epoch 192/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.0106 - accuracy: 0.0623\n",
      "Epoch 193/200\n",
      "32/32 [==============================] - 1s 38ms/step - loss: 4.0236 - accuracy: 0.0589\n",
      "Epoch 194/200\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 3.9905 - accuracy: 0.0682\n",
      "Epoch 195/200\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 3.9987 - accuracy: 0.0618\n",
      "Epoch 196/200\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.0008 - accuracy: 0.0668\n",
      "Epoch 197/200\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 3.9985 - accuracy: 0.0649\n",
      "Epoch 198/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 3.9870 - accuracy: 0.0650\n",
      "Epoch 199/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 3.9620 - accuracy: 0.0679\n",
      "Epoch 200/200\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 4.0006 - accuracy: 0.0604\n",
      "8/8 [==============================] - 1s 22ms/step - loss: 4.3065 - accuracy: 0.0520\n",
      "Baseline: 3.82% (1.42%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=1024, verbose=1)\n",
    "\n",
    "results = cross_val_score(estimator, train_X.values, onehot_Y, cv=KFold(n_splits=5, shuffle=True))\n",
    "\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automlschool",
   "language": "python",
   "name": "automlschool"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
